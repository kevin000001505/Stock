from auth import check_authentication, show_logout_button
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from stock import StockDataFetcher
import datetime
import time
import config


BASE_COLUMNS = ["ä»£è™Ÿ", "åç¨±", "ç”¢æ¥­åˆ¥"]

check_authentication()

st.set_page_config(page_title="Stock Data Analysis", layout="wide")

show_logout_button()

# Initialize the StockDataFetcher
stock_fetcher = StockDataFetcher()

st.sidebar.header("åƒæ•¸èª¿æ•´")

# Stock type selection
stock_type = st.sidebar.radio("å¸‚å ´", ["ä¸Šå¸‚", "ä¸Šæ«ƒ"])

# Number of extrema to find
num_extrema = st.sidebar.slider("é¡¯ç¤ºåº•æˆ–é ‚æ•¸é‡", 2, 10, 2)

# Extrema type - Modified to include "Both" option
extrema_display = st.sidebar.radio("ç¯©é¸æ–¹å¼", ["åº•è°·", "é ‚å³°", "å…©è€…"])

# Map Chinese to English for internal use
extrema_mapping = {"åº•è°·": "Minima", "é ‚å³°": "Maxima", "å…©è€…": "Both"}

extrema_type = extrema_mapping[extrema_display]

# Reverse option - Changed to radio button with Chinese labels
reverse_display = st.sidebar.radio("æ¯”è¼ƒæ–¹å‘", ["åšå¤š", "åšç©º"])

# Map Chinese to English/Boolean for internal use
reverse_option = True if reverse_display == "åšç©º" else False

# Moving Average controls in sidebar
st.sidebar.header("ç§»å‹•å¹³å‡æ•¸")
window_size = st.sidebar.slider("å¤©æ•¸", 1, 10, 1)

# Add data display range control
st.sidebar.header("è³‡æ–™é¡¯ç¤ºç¯„åœ")
display_days = st.sidebar.slider("é¡¯ç¤ºå¤©æ•¸", 5, 100, 20, help="é¸æ“‡è¦é¡¯ç¤ºçš„è³‡æ–™å¤©æ•¸")


def get_today_date():
    """Get today's date in M/D format (cross-platform)"""
    today = datetime.datetime.now()
    return f"{today.month:02d}/{today.day:02d}"


# Get current date dynamically
current_date = get_today_date()

# Check if current date data already exists
if stock_type == "ä¸Šå¸‚":
    market_df = stock_fetcher.listed_data
else:
    market_df = stock_fetcher.counter_data

has_current_data = current_date in market_df.columns

# Button to fetch latest data
if st.sidebar.button("ç²å–ä»Šæ—¥è‚¡ç¥¨è³‡æ–™"):
    if has_current_data:
        st.info(f"Data for {current_date} already exists. No fetch needed.")
    else:
        with st.spinner("ç²å–æœ€æ–°è‚¡ç¥¨è³‡è¨Š..."):
            try:
                if stock_type == "ä¸Šå¸‚":
                    market_df = stock_fetcher.fetch_stock_data(market_df, "listed")
                else:
                    market_df = stock_fetcher.fetch_stock_data(market_df, "counter")

                st.success("è³‡æ–™æ›´æ–°æˆåŠŸï¼")
                # Force app to rerun and recalculate all variables
                st.rerun()

            except Exception as e:
                st.error(f"ç²å–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

# Display current data status
if has_current_data:
    st.sidebar.success(f"âœ… Data for {current_date} is available")
else:
    st.sidebar.warning(f"âš ï¸ Data for {current_date} is missing")

# Show data overview with filtered dataframe based on extrema results
st.header(f"{stock_type} è‚¡ç¥¨æ•¸æ“šæ¦‚è¦½")


def prepare_series(
    values: np.ndarray,
    labels: np.ndarray,
    window_size: int,
    display_days: int,
) -> tuple[np.ndarray, np.ndarray]:
    """Apply moving average and trim to the requested display window."""

    processed_values = values
    processed_labels = labels

    if window_size > 1 and values.size >= window_size:
        kernel = np.ones(window_size) / window_size
        processed_values = np.convolve(values, kernel, mode="valid")
        processed_labels = labels[window_size - 1 :]

    if display_days and processed_values.size > display_days:
        processed_values = processed_values[-display_days:]
        processed_labels = processed_labels[-display_days:]

    return processed_values, processed_labels


category_options = (
    sorted(market_df["ç”¢æ¥­åˆ¥"].dropna().unique()) if "ç”¢æ¥­åˆ¥" in market_df.columns else []
)

selected_categories = st.sidebar.multiselect(
    "ç”¢æ¥­åˆ¥",
    options=category_options,
    default=category_options,
    placeholder="é¸æ“‡æ¬²åˆ†æçš„ç”¢æ¥­åˆ¥",
    help="ä¾ç…§è‚¡ç¥¨ç”¢æ¥­åˆ¥ç¯©é¸è³‡æ–™ï¼Œé è¨­ç‚ºå…¨éƒ¨ç”¢æ¥­",
)

if selected_categories:
    filtered_market_df = market_df[market_df["ç”¢æ¥­åˆ¥"].isin(selected_categories)].copy()
else:
    filtered_market_df = market_df.iloc[0:0].copy()

filtered_market_df.reset_index(drop=True, inplace=True)

display_df = pd.DataFrame(columns=BASE_COLUMNS)
price_columns = [col for col in filtered_market_df.columns if col not in BASE_COLUMNS]
total_considered = len(filtered_market_df)
has_category_selection = bool(selected_categories)

if total_considered and price_columns:
    numeric_prices = filtered_market_df.loc[:, price_columns].apply(
        pd.to_numeric, errors="coerce"
    )
    price_matrix = numeric_prices.to_numpy(dtype=float)
    price_labels = np.array(price_columns)

    filtered_records: list[dict] = []

    with st.spinner("Analyzing all stocks for positive trends..."):
        for row_idx in range(total_considered):
            row_prices = price_matrix[row_idx]
            valid_mask = ~np.isnan(row_prices)

            if valid_mask.sum() < 3:
                continue

            valid_values = row_prices[valid_mask]
            valid_labels = price_labels[valid_mask]

            processed_values, processed_labels = prepare_series(
                valid_values, valid_labels, window_size, display_days
            )

            if processed_values.size < 3:
                continue

            series_for_analysis = processed_values.tolist()

            try:
                if extrema_type == "Both":
                    minima_result, _ = stock_fetcher.find_local_extrema(
                        series_for_analysis,
                        find_type="minima",
                        number_of_extrema=num_extrema,
                        reverse=reverse_option,
                    )
                    maxima_result, _ = stock_fetcher.find_local_extrema(
                        series_for_analysis,
                        find_type="maxima",
                        number_of_extrema=num_extrema,
                        reverse=reverse_option,
                    )
                    matches_filter = minima_result and maxima_result
                else:
                    matches_filter, _ = stock_fetcher.find_local_extrema(
                        series_for_analysis,
                        find_type=extrema_type.lower(),
                        number_of_extrema=num_extrema,
                        reverse=reverse_option,
                    )
            except Exception:
                continue

            if not matches_filter:
                continue

            stock_info = filtered_market_df.loc[row_idx, BASE_COLUMNS].to_dict()
            record = {**stock_info}
            record.update(
                {
                    label: round(value, 2)
                    for label, value in zip(processed_labels.tolist(), processed_values)
                }
            )
            filtered_records.append(record)

    if filtered_records:
        display_df = pd.DataFrame(filtered_records)

        ordered_date_columns = [
            col for col in price_columns if col in display_df.columns and col not in BASE_COLUMNS
        ]

        if display_days and len(ordered_date_columns) > display_days:
            ordered_date_columns = ordered_date_columns[-display_days:]

        final_columns = BASE_COLUMNS + ordered_date_columns
        display_df = display_df.reindex(columns=final_columns)
        display_df.sort_values(by="ä»£è™Ÿ", inplace=True)
        display_df.reset_index(drop=True, inplace=True)
        display_df["ä»£è™Ÿ"] = display_df["ä»£è™Ÿ"].astype(str)
    else:
        display_df = pd.DataFrame(columns=BASE_COLUMNS)
else:
    if not has_category_selection and category_options:
        st.sidebar.warning("âš ï¸ è«‹é¸æ“‡è‡³å°‘ä¸€å€‹ç”¢æ¥­åˆ¥é€²è¡Œç¯©é¸")

if not display_df.empty:
    st.success(
        f"Found {len(display_df)} stocks with positive trends out of {total_considered} total stocks"
    )
else:
    if not has_category_selection and not category_options:
        st.info("ğŸš« æ­¤å¸‚å ´å°šæœªæä¾›ç”¢æ¥­åˆ¥è³‡æ–™")
    elif not has_category_selection:
        st.info("ğŸ‘ˆ åœ¨å´é‚Šæ¬„é¸æ“‡æ¬²åˆ†æçš„ç”¢æ¥­åˆ¥å¾Œå³å¯é¡¯ç¤ºçµæœ")
    elif total_considered == 0:
        st.error("âŒ é¸å®šçš„ç”¢æ¥­åˆ¥ç›®å‰æ²’æœ‰å¯ç”¨è‚¡ç¥¨è³‡æ–™")
    else:
        st.error("âŒ æ²’æœ‰è‚¡ç¥¨ç¬¦åˆæ‚¨è¨­å®šçš„æ¢ä»¶")

        # Show what the user was looking for
        st.info("**æ‚¨çš„ç¯©é¸æ¢ä»¶:**")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"- å¸‚å ´: **{stock_type}**")
            st.write(f"- ç¯©é¸æ–¹å¼: **{extrema_display}**")
            st.write(f"- æ¯”è¼ƒæ–¹å‘: **{reverse_display}**")
            st.write(
                "- ç”¢æ¥­åˆ¥: "
                + ("å…¨éƒ¨" if len(selected_categories) == len(category_options) else ", ".join(selected_categories))
            )
        with col2:
            st.write(f"- åº•/é ‚æ•¸é‡: **{num_extrema}**")
            st.write(f"- ç§»å‹•å¹³å‡: **{window_size} å¤©**")
            st.write(f"- é¡¯ç¤ºç¯„åœ: **{display_days} å¤©**")

        display_df = pd.DataFrame(columns=BASE_COLUMNS)

st.write(f"è‚¡ç¥¨æ•¸: {len(display_df)}")

# Display the filtered dataframe with scrolling capability
if len(display_df) > 0:
    # Add download button for filtered data
    if not display_df.empty:
        price_cols_for_download = [
            col for col in display_df.columns if col not in BASE_COLUMNS
        ]

        if price_cols_for_download:
            download_columns = ["ä»£è™Ÿ", "åç¨±", price_cols_for_download[-1]]
        else:
            download_columns = ["ä»£è™Ÿ", "åç¨±", "ç”¢æ¥­åˆ¥"]

        download_df = display_df.loc[:, download_columns].copy()

        download_df["ä»£è™Ÿ"] = download_df["ä»£è™Ÿ"].astype(str)
        # Convert to CSV
        csv = download_df.to_csv(index=False, encoding="utf-8-sig")

        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ç•¶æ—¥ç¬¦åˆè‚¡ç¥¨ (CSV)",
            data=csv.encode("utf-8-sig"),  # Add this encoding
            file_name=f"{stock_type}_{current_date}.csv",
            mime="text/csv; charset=utf-8",  # Specify charset
            help="ä¸‹è¼‰åŒ…å«è‚¡ç¥¨ä»£è™Ÿã€åç¨±å’Œæœ€æ–°åƒ¹æ ¼çš„è³‡æ–™",
        )

    # Make the dataframe clickable
    event = st.dataframe(
        display_df,
        use_container_width=True,
        height=400,
        on_select="rerun",
        selection_mode="single-row",
    )

    # Get the selected stock from dataframe click
    selected_stock_from_df = None
    if event.selection and len(event.selection.rows) > 0:
        selected_row_index = event.selection.rows[0]
        selected_stock_from_df = display_df.iloc[selected_row_index]["ä»£è™Ÿ"]
else:
    if has_category_selection and total_considered > 0:
        st.info("ğŸš« æ²’æœ‰è‚¡ç¥¨ç¬¦åˆæ‚¨çš„ç¯©é¸æ¢ä»¶")
    elif not has_category_selection:
        st.info("ğŸ‘ˆ åœ¨å´é‚Šæ¬„é¸æ“‡ç”¢æ¥­åˆ¥å¾Œå³å¯é¡¯ç¤ºè‚¡ç¥¨æ¸…å–®")
    else:
        st.info("ğŸš« æ­¤å¸‚å ´æš«æ™‚æ²’æœ‰å¯é¡¯ç¤ºçš„è‚¡ç¥¨è³‡æ–™")

# Stock filter (now works on the already filtered data)
st.header("è‚¡ç¥¨åˆ†æ")
stock_filter = st.text_input("Filter stocks by code or name", "")

filtered_df = display_df
if stock_filter and len(display_df) > 0:
    filtered_df = display_df[
        display_df["ä»£è™Ÿ"].str.contains(stock_filter, na=False)
        | display_df["åç¨±"].str.contains(stock_filter, na=False)
    ]

if not filtered_df.empty:
    # Use selected stock from dataframe click or selectbox
    if (
        selected_stock_from_df
        and selected_stock_from_df in filtered_df["ä»£è™Ÿ"].tolist()
    ):
        selected_stock = selected_stock_from_df
        # Update selectbox to show the clicked stock
        stock_options = filtered_df["ä»£è™Ÿ"].tolist()
        default_index = (
            stock_options.index(selected_stock)
            if selected_stock in stock_options
            else 0
        )
        selected_stock = st.selectbox(
            "Select a Stock", stock_options, index=default_index
        )
    else:
        # Allow user to select a stock normally
        selected_stock = st.selectbox("Select a Stock", filtered_df["ä»£è™Ÿ"].tolist())

    # Get the selected stock data - USE THE SAME RAW DATA SOURCE
    stock_row = market_df[market_df["ä»£è™Ÿ"] == selected_stock].iloc[
        0
    ]
    stock_name = stock_row["åç¨±"]

    st.subheader(f"{selected_stock} - {stock_name}")

    # Get the price data columns from original df
    price_columns = [col for col in market_df.columns if col not in BASE_COLUMNS]

    # Extract RAW price data for the selected stock
    raw_price_series = pd.to_numeric(
        stock_row[price_columns], errors="coerce"
    )
    price_array = raw_price_series.to_numpy(dtype=float)
    price_labels = np.array(price_columns)

    valid_mask = ~np.isnan(price_array)
    valid_values = price_array[valid_mask]
    valid_labels = price_labels[valid_mask]

    # Find local extrema
    if valid_values.size >= 3:
        use_moving_average = window_size > 1 and valid_values.size >= window_size
        processed_values, processed_labels = prepare_series(
            valid_values, valid_labels, window_size, display_days
        )

        if processed_values.size < 3:
            st.warning("Not enough processed price data for analysis after trimming.")
        else:
            data_to_analyze = processed_values.tolist()
            labels_to_use = processed_labels.tolist()
            line_label = (
                f"Moving Average ({window_size})" if use_moving_average else "Price"
            )
            line_color = "orange" if use_moving_average else "steelblue"

            # Now the extrema detection uses the SAME processed data as filtering
            if extrema_type == "Both":
                # Find minima on filtered data
                minima_result, minima_locations = stock_fetcher.find_local_extrema(
                    data_to_analyze,
                    find_type="minima",
                    number_of_extrema=num_extrema,
                    reverse=reverse_option,
                )

                # Find maxima on filtered data
                maxima_result, maxima_locations = stock_fetcher.find_local_extrema(
                    data_to_analyze,
                    find_type="maxima",
                    number_of_extrema=num_extrema,
                    reverse=reverse_option,
                )

                # Line plot with highlighted extrema points
                plt.style.use("seaborn-v0_8")
                fig, ax = plt.subplots(figsize=(14, 8))

                # Create x-axis positions based on filtered data length - FIX HERE
                x_positions = range(len(data_to_analyze))
                x_labels = labels_to_use[: len(data_to_analyze)]  # Ensure same length

                sns.lineplot(
                    x=x_positions,
                    y=data_to_analyze,
                    marker="o",
                    linewidth=3,
                    markersize=8,
                    color=line_color,
                    alpha=0.8,
                    ax=ax,
                    label=line_label,
                )

                # Highlight minima points if found
                if minima_locations:
                    minima_values = [data_to_analyze[loc] for loc in minima_locations]
                    ax.scatter(
                        minima_locations,
                        minima_values,
                        color="red",
                        s=200,
                        marker="v",
                        label="Local Minima",
                        zorder=5,
                        edgecolor="darkred",
                        linewidth=2,
                    )

                    # Draw connecting line between minima points
                    if len(minima_locations) > 1:
                        ax.plot(
                            minima_locations,
                            minima_values,
                            color="red",
                            linestyle="--",
                            linewidth=2,
                            alpha=0.7,
                            label="Minima Trend Line",
                        )

                    # Add annotations for minima with price values
                    for i, loc in enumerate(minima_locations):
                        ax.annotate(
                            f"{data_to_analyze[loc]:.2f}",
                            xy=(loc, data_to_analyze[loc]),
                            xytext=(0, -20),
                            textcoords="offset points",
                            bbox=dict(boxstyle="round,pad=0.3", fc="red", alpha=0.8),
                            arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"),
                            fontsize=12,
                            color="white",
                            weight="bold",
                            ha="center",
                        )

                # Highlight maxima points if found
                if maxima_locations:
                    maxima_values = [data_to_analyze[loc] for loc in maxima_locations]
                    ax.scatter(
                        maxima_locations,
                        maxima_values,
                        color="green",
                        s=200,
                        marker="^",
                        label="Local Maxima",
                        zorder=5,
                        edgecolor="darkgreen",
                        linewidth=2,
                    )

                    # Draw connecting line between maxima points
                    if len(maxima_locations) > 1:
                        ax.plot(
                            maxima_locations,
                            maxima_values,
                            color="green",
                            linestyle="--",
                            linewidth=2,
                            alpha=0.7,
                            label="Maxima Trend Line",
                        )

                    # Add annotations for maxima with price values
                    for i, loc in enumerate(maxima_locations):
                        ax.annotate(
                            f"{data_to_analyze[loc]:.2f}",
                            xy=(loc, data_to_analyze[loc]),
                            xytext=(0, 20),
                            textcoords="offset points",
                            bbox=dict(boxstyle="round,pad=0.3", fc="green", alpha=0.8),
                            arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0"),
                            fontsize=12,
                            color="white",
                            weight="bold",
                            ha="center",
                        )

                ax.set_xlabel("Date", fontsize=14, fontweight="bold")
                ax.set_ylabel("Price", fontsize=14, fontweight="bold")

                # Set x-axis labels - now correctly sized for filtered data
                ax.set_xticks(x_positions)
                ax.set_xticklabels(x_labels, rotation=45, ha="right")

                # Add grid with better styling
                ax.grid(True, alpha=0.3, linestyle="--")

                # Add legend if there are extrema points
                if minima_locations or maxima_locations:
                    ax.legend(fontsize=12, loc="upper left")

                # Add subtle background color
                ax.set_facecolor("#f8f9fa")

                # Tight layout to prevent label cutoff
                plt.tight_layout()

                st.pyplot(fig)

                # Show extrema values for both (using correct labels)
                st.subheader("è©³ç´°è³‡è¨Š")

                col1, col2 = st.columns(2)

                with col1:
                    st.write("**Minima Details:**")
                    if minima_locations:
                        minima_data = []
                        for i, loc in enumerate(minima_locations):
                            minima_data.append(
                                {
                                    "Date": labels_to_use[loc],
                                    "Position": loc,
                                    "Value": data_to_analyze[loc],
                                    "Type": "Minimum",
                                }
                            )
                        minima_df = pd.DataFrame(minima_data)
                        st.dataframe(minima_df, use_container_width=True)
                    else:
                        st.info("No minima found")

                with col2:
                    st.write("**Maxima Details:**")
                    if maxima_locations:
                        maxima_data = []
                        for i, loc in enumerate(maxima_locations):
                            maxima_data.append(
                                {
                                    "Date": labels_to_use[loc],
                                    "Position": loc,
                                    "Value": data_to_analyze[loc],
                                    "Type": "Maximum",
                                }
                            )
                        maxima_df = pd.DataFrame(maxima_data)
                        st.dataframe(maxima_df, use_container_width=True)
                    else:
                        st.info("No maxima found")

            else:
                # Single extrema type visualization
                result, locations = stock_fetcher.find_local_extrema(
                    data_to_analyze,
                    find_type=extrema_type.lower(),
                    number_of_extrema=num_extrema,
                    reverse=reverse_option,
                )

                if result is not None and locations:  # Check for valid results
                    plt.style.use("seaborn-v0_8")
                    fig, ax = plt.subplots(figsize=(14, 8))

                    # Create x-axis positions based on filtered data length - FIX HERE
                    x_positions = range(len(data_to_analyze))
                    x_labels = labels_to_use[: len(data_to_analyze)]  # Ensure same length

                    sns.lineplot(
                        x=x_positions,
                        y=data_to_analyze,
                        marker="o",
                        linewidth=3,
                        markersize=8,
                        color=line_color,
                        alpha=0.8,
                        ax=ax,
                        label=line_label,
                    )

                    # Highlight the extrema points
                    if locations:
                        extrema_values = [data_to_analyze[loc] for loc in locations]
                        if extrema_type == "Minima":
                            ax.scatter(
                                locations,
                                extrema_values,
                                color="red",
                                s=200,
                                marker="v",
                                label="Local Minima",
                                zorder=5,
                                edgecolor="darkred",
                                linewidth=2,
                            )

                            # Draw connecting line between minima points with dashed line
                            if len(locations) > 1:
                                ax.plot(
                                    locations,
                                    extrema_values,
                                    color="red",
                                    linestyle="--",
                                    linewidth=2,
                                    alpha=0.7,
                                    label="Minima Trend Line",
                                )

                            # Add price annotations for minima
                            for i, loc in enumerate(locations):
                                ax.annotate(
                                    f"{data_to_analyze[loc]:.2f}",
                                    xy=(loc, data_to_analyze[loc]),
                                    xytext=(0, -20),
                                    textcoords="offset points",
                                    bbox=dict(
                                        boxstyle="round,pad=0.3", fc="red", alpha=0.8
                                    ),
                                    arrowprops=dict(
                                        arrowstyle="->", connectionstyle="arc3,rad=0"
                                    ),
                                    fontsize=12,
                                    color="white",
                                    weight="bold",
                                    ha="center",
                                )

                        else:
                            ax.scatter(
                                locations,
                                extrema_values,
                                color="green",
                                s=200,
                                marker="^",
                                label="Local Maxima",
                                zorder=5,
                                edgecolor="darkgreen",
                                linewidth=2,
                            )

                            # Draw connecting line between maxima points with dashed line
                            if len(locations) > 1:
                                ax.plot(
                                    locations,
                                    extrema_values,
                                    color="green",
                                    linestyle="--",
                                    linewidth=2,
                                    alpha=0.7,
                                    label="Maxima Trend Line",
                                )

                            # Add price annotations for maxima
                            for i, loc in enumerate(locations):
                                ax.annotate(
                                    f"{data_to_analyze[loc]:.2f}",
                                    xy=(loc, data_to_analyze[loc]),
                                    xytext=(0, 20),
                                    textcoords="offset points",
                                    bbox=dict(
                                        boxstyle="round,pad=0.3", fc="green", alpha=0.8
                                    ),
                                    arrowprops=dict(
                                        arrowstyle="->", connectionstyle="arc3,rad=0"
                                    ),
                                    fontsize=12,
                                    color="white",
                                    weight="bold",
                                    ha="center",
                                )

                    ax.set_xlabel("Date", fontsize=14, fontweight="bold")
                    ax.set_ylabel("Price", fontsize=14, fontweight="bold")

                    # Set x-axis labels - now correctly sized for filtered data
                    ax.set_xticks(x_positions)
                    ax.set_xticklabels(x_labels, rotation=45, ha="right")

                    # Add grid with better styling
                    ax.grid(True, alpha=0.3, linestyle="--")

                    # Add legend
                    ax.legend(fontsize=12, loc="upper left")

                    # Add subtle background color
                    ax.set_facecolor("#f8f9fa")

                    # Tight layout to prevent label cutoff
                    plt.tight_layout()

                    st.pyplot(fig)

                    # Show extrema values (using correct labels)
                    st.subheader("è©³ç´°è³‡è¨Š")
                    extrema_data = []
                    for i, loc in enumerate(locations):
                        extrema_data.append(
                            {
                                "æ—¥æœŸ": labels_to_use[loc],
                                # "Position": loc,
                                "åƒ¹æ ¼": data_to_analyze[loc],
                                "ç¯©é¸æ–¹å¼": extrema_display,
                            }
                        )

                    extrema_df = pd.DataFrame(extrema_data)
                    st.dataframe(extrema_df, use_container_width=True)
                else:
                    st.warning(f"âŒ ç„¡æ³•æ‰¾åˆ°è¶³å¤ çš„{extrema_display}é€²è¡Œåˆ†æ")
                    st.info(f"æ­¤è‚¡ç¥¨åœ¨è¨­å®šæ¢ä»¶ä¸‹æ‰¾ä¸åˆ° {num_extrema} å€‹{extrema_display}")
    else:
        st.warning("Not enough price data for this stock to perform analysis.")
else:
    st.info("ğŸš« æ²’æœ‰è‚¡ç¥¨ç¬¦åˆæ‚¨çš„ç¯©é¸æ¢ä»¶")

    # Show current parameter settings for user reference
    st.markdown("**ç›®å‰è¨­å®š:**")
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"- å¸‚å ´: **{stock_type}**")
        st.write(f"- ç¯©é¸æ–¹å¼: **{extrema_display}**")
        st.write(f"- æ¯”è¼ƒæ–¹å‘: **{reverse_display}**")
    with col2:
        st.write(f"- åº•/é ‚æ•¸é‡: **{num_extrema}**")
        st.write(f"- ç§»å‹•å¹³å‡: **{window_size} å¤©**")
        st.write(f"- é¡¯ç¤ºç¯„åœ: **{display_days} å¤©**")

# Add CSV Editor Section in Sidebar
st.sidebar.header("ğŸ“ è³‡æ–™ç®¡ç†")

with st.sidebar.expander("åˆªé™¤æ—¥æœŸç¯„åœè³‡æ–™"):
    st.info("åˆªé™¤æŒ‡å®šæ—¥æœŸç¯„åœçš„è‚¡åƒ¹è³‡æ–™æ¬„ä½")

    # Get current year for date context
    current_year = datetime.datetime.now().year

    # Date range input with date picker
    start_date_picker = st.date_input(
        "é–‹å§‹æ—¥æœŸ", value=datetime.date(current_year, 1, 1), help="é¸æ“‡é–‹å§‹æ—¥æœŸ"
    )

    end_date_picker = st.date_input(
        "çµæŸæ—¥æœŸ", value=datetime.date(current_year, 4, 1), help="é¸æ“‡çµæŸæ—¥æœŸ"
    )

    if start_date_picker and end_date_picker:
        # Convert to MM/DD format for matching
        start_date_str = (
            start_date_picker.strftime("%m/%d").lstrip("0").replace("/0", "/")
        )
        end_date_str = end_date_picker.strftime("%m/%d").lstrip("0").replace("/0", "/")

        # Get current dataframe
        current_df = (
            stock_fetcher.listed_data
            if stock_type == "ä¸Šå¸‚"
            else stock_fetcher.counter_data
        )

        # Get date columns
        date_columns = [
            col for col in current_df.columns if col not in BASE_COLUMNS
        ]

        # Filter columns by date range
        columns_to_delete = []
        for col in date_columns:
            try:
                # Parse column date
                col_parts = col.split("/")
                if len(col_parts) == 2:
                    col_month, col_day = int(col_parts[0]), int(col_parts[1])
                    col_date = datetime.date(current_year, col_month, col_day)

                    # Check if in range
                    if start_date_picker <= col_date <= end_date_picker:
                        columns_to_delete.append(col)

            except (ValueError, IndexError):
                continue

        # Show preview and delete functionality
        if columns_to_delete:
            st.warning(f"âš ï¸ å°‡åˆªé™¤ {len(columns_to_delete)} å€‹æ—¥æœŸæ¬„ä½")

            # Show first few columns as preview
            preview_cols = columns_to_delete[:5]
            if len(columns_to_delete) > 5:
                st.write(
                    f"ğŸ“‹ é è¦½: {', '.join(preview_cols)}... (+{len(columns_to_delete)-5} æ›´å¤š)"
                )
            else:
                st.write(f"ğŸ“‹ å°‡åˆªé™¤: {', '.join(preview_cols)}")

            if st.button("ğŸ—‘ï¸ ç¢ºèªåˆªé™¤", type="secondary"):
                with st.spinner("æ­£åœ¨åˆªé™¤æ¬„ä½..."):
                    try:
                        # Delete and save
                        if stock_type == "ä¸Šå¸‚":
                            stock_fetcher.listed_data = stock_fetcher.listed_data.drop(
                                columns=columns_to_delete
                            )
                            stock_fetcher.listed_data.to_csv(
                                config.LISTED_CSV, index=False, encoding="utf-8-sig"
                            )
                        else:
                            stock_fetcher.counter_data = (
                                stock_fetcher.counter_data.drop(
                                    columns=columns_to_delete
                                )
                            )
                            stock_fetcher.counter_data.to_csv(
                                config.COUNTER_CSV, index=False, encoding="utf-8-sig"
                            )

                        st.success(f"âœ… æˆåŠŸåˆªé™¤ {len(columns_to_delete)} å€‹æ¬„ä½ï¼")
                        time.sleep(1)
                        st.rerun()

                    except Exception as e:
                        st.error(f"åˆªé™¤å¤±æ•—: {str(e)}")
        else:
            st.info("ğŸ“… æŒ‡å®šç¯„åœå…§ç„¡åŒ¹é…çš„æ—¥æœŸæ¬„ä½")

st.sidebar.markdown("---")
